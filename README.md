# âœ¨ Gesture Ink â€“ Hand Gesture Writing & Drawing System

**Gesture Ink** is a real-time, no-touch writing and drawing system powered by **computer vision**, **MQTT**, and **wearable technology**.  
It lets users write or draw mid-air using hand gestures alone â€” perfect for **digital art**, **assistive tools**, and **smart presentations**.

Developed at **MakeUofT 2025 (Canadaâ€™s Largest Makeathon)**, this project was awarded recognition for its innovation in **gesture-based interfaces** and **IoT integration**.

---

## ğŸ“½ï¸ Demo & Live Preview

ğŸ¥ **[Watch the Full Demo on YouTube](https://youtu.be/lAq6rWafrmU)**

---

## ğŸ–¼ï¸ Highlights from Gesture Ink

### âœï¸ Gesture-Based Drawing  
> âœŒï¸ Two fingers up â†’ Draw mode  
![Gesture Drawing](https://github.com/user-attachments/assets/432637c5-4906-4aa1-b9c5-b3850cd591fe)

### ğŸŒˆ Dynamic Color Switching via Glove Sensors  
> ğŸ§¤ Real-time RGB control during our MakeUofT demo  
![Color Change](https://github.com/user-attachments/assets/93cde095-60f9-4f15-bd4d-9df8ed427bb9)

![Team Presentation](https://github.com/user-attachments/assets/cd8db60f-47e6-4059-8a00-c65dbf8d277c)

---

## ğŸš€ Core Features

### 1ï¸âƒ£ âœï¸ Gesture-Based Drawing & Writing  
- âœŒï¸ Two fingers up â†’ Start drawing  
- â˜ï¸ One finger up â†’ Continue drawing  
- ğŸ¤Ÿ Three fingers up â†’ Undo  
- âœŠ Fist â†’ Stop drawing  

### 2ï¸âƒ£ ğŸŒˆ Dynamic Color Selection (MQTT-Driven)  
- Live RGB changes from glove sensors  
- Color switching without touching the screen  

### 3ï¸âƒ£ ğŸ”Š Boundary Detection + Buzzer Alerts  
- Sends out-of-bounds alert via MQTT  
- Glove buzzer provides tactile feedback  

### 4ï¸âƒ£ ğŸ“¡ Real-Time MQTT Communication  
- Subscribes to live glove sensor values  
- Publishes buzzer triggers and actions  

### 5ï¸âƒ£ ğŸ“· Computer Vision + Hand Tracking  
- Uses OpenCV and cvzone for gesture detection  
- Real-time visual feedback and accuracy  

### 6ï¸âƒ£ ğŸ”„ Undo + Reset Capabilities  
- Gesture-based undo action  
- Clear screen with a reset motion  

---

## ğŸ› ï¸ Tech Stack & Tools

### ğŸ’» Software  
- **Python 3.12+**  
- **OpenCV** for video capture and processing  
- **cvzone + MediaPipe** for hand tracking  
- **NumPy** for image manipulation  
- **paho-mqtt** for communication

### ğŸ”§ Hardware  
- **Arduino glove sensors** (flex sensors + RGB)  
- **Buzzer module**  
- **ESP32 / ESP8266** for MQTT connectivity  
- **Webcam** for hand tracking  

### ğŸ”— Languages & Protocols  
- **Python** â†’ main logic  
- **C++ (Arduino IDE)** â†’ glove firmware  
- **MQTT** â†’ real-time, wireless communication  

---

### ğŸ”Œ Hardware Setup

Connect the **ESP32** and upload the glove firmware via **Arduino IDE**.  
Attach **flex sensors** to detect finger gestures.  
Connect a **buzzer** for out-of-bound alerts.  
Set up an **MQTT broker** (e.g., Mosquitto) and configure IPs in the Python script.

---

### ğŸ”® Future Enhancements

#### âœï¸ AI-Based Handwriting Recognition  
- Translate air-written strokes into editable text  
- Potential use of Googleâ€™s handwriting API or ML model

#### ğŸ–Šï¸ Pressure-Based Brush Control  
- Use sensor data to vary stroke thickness  
- Speed-sensitive brush dynamics

#### ğŸ•¶ï¸ VR/AR Compatibility  
- Create a virtual whiteboard in 3D  
- Support Leap Motion / Meta Quest tracking

#### â˜ï¸ Cloud Sync & Multi-Device Support  
- Store notes/drawings via Firebase or Google Drive  
- Access from any device
## ğŸ§ª Installation Guide

### âœ… Install Dependencies  
Make sure you have Python installed, then run:

```bash
pip install opencv-python numpy cvzone paho-mqtt
---
